{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "gdl_code_2",
      "language": "python",
      "name": "gdl_code_2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "03_01_autoencoder_train.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kurikinton105/GDL_code_colab/blob/main/03_01_autoencoder_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfQS7nNLbY0Z"
      },
      "source": [
        "# Autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isGi7rTIbaW1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8ae35ced-03e2-402b-a344-e76e22d28e03"
      },
      "source": [
        "pip install tensorflow==2.1.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==2.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/d4/c0cd1057b331bc38b65478302114194bd8e1b9c2bbc06e300935c0e93d90/tensorflow-2.1.0-cp36-cp36m-manylinux2010_x86_64.whl (421.8MB)\n",
            "\u001b[K     |████████████████████████████████| 421.8MB 19kB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.30.0)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (3.2.1)\n",
            "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.4.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.8.1)\n",
            "Collecting tensorflow-estimator<2.2.0,>=2.1.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/90/b77c328a1304437ab1310b463e533fa7689f4bfc41549593056d812fab8e/tensorflow_estimator-2.1.0-py2.py3-none-any.whl (448kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 37.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.2.0)\n",
            "Collecting tensorboard<2.2.0,>=2.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d9/41/bbf49b61370e4f4d245d4c6051dfb6db80cec672605c91b1652ac8cc3d38/tensorboard-2.1.1-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.9MB 39.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.12.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.1.2)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.34.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.12.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.9.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (3.10.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.0.8)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.18.5)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.2.2)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.17.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.4.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (47.3.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2.23.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==2.1.0) (2.10.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.6.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (4.1.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (4.6)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.3.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.1.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.1.0)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7540 sha256=c7683e6524b849c983e3bc5eef4332cb51cb3b53638439ad75df9a9ffc64681d\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow-probability 0.10.0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: gast, tensorflow-estimator, tensorboard, tensorflow\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorflow-estimator 2.2.0\n",
            "    Uninstalling tensorflow-estimator-2.2.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.2.0\n",
            "  Found existing installation: tensorboard 2.2.2\n",
            "    Uninstalling tensorboard-2.2.2:\n",
            "      Successfully uninstalled tensorboard-2.2.2\n",
            "  Found existing installation: tensorflow 2.2.0\n",
            "    Uninstalling tensorflow-2.2.0:\n",
            "      Successfully uninstalled tensorflow-2.2.0\n",
            "Successfully installed gast-0.2.2 tensorboard-2.1.1 tensorflow-2.1.0 tensorflow-estimator-2.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3MdbKLZcSBZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "7ba899dc-6d55-41ea-dda9-bd30f6d16fa7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEDHOcgCcYZj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3cad40f3-7d7b-4317-bf62-a18b2779f9dd"
      },
      "source": [
        "cd /content/drive/My Drive/Colab Notebooks/GDL/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/GDL\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rwF7olR6I8k",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        },
        "outputId": "f2a8ba47-5573-40f7-a608-c25b1f44bb9a"
      },
      "source": [
        "ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "02_01_deep_learning_deep_neural_network.ipynb\n",
            "02_02_deep_learning_convolutions.ipynb\n",
            "02_03_deep_learning_conv_neural_network.ipynb\n",
            "03_01_autoencoder_train.ipynb\n",
            "03_02_autoencoder_analysis.ipynb\n",
            "03_03_vae_digits_train.ipynb\n",
            "03_04_vae_digits_analysis.ipynb\n",
            "03_05_vae_faces_train.ipynb\n",
            "03_06_vae_faces_analysis.ipynb\n",
            "04_01_gan_camel_train.ipynb\n",
            "04_02_wgan_cifar_train.ipynb\n",
            "04_03_wgangp_faces_train.ipynb\n",
            "05_01_cyclegan_train.ipynb\n",
            "06_01_lstm_text_train.ipynb\n",
            "06_02_qa_train.ipynb\n",
            "06_03_qa_analysis.ipynb\n",
            "07_01_notation_compose.ipynb\n",
            "07_02_lstm_compose_train.ipynb\n",
            "07_03_lstm_compose_predict.ipynb\n",
            "07_04_musegan_train.ipynb\n",
            "07_05_musegan_analysis.ipynb\n",
            "09_01_positional_encoding.ipynb\n",
            "\u001b[0m\u001b[01;34mcode_before\u001b[0m/\n",
            "\u001b[01;34mcodebefore2\u001b[0m/\n",
            "\u001b[01;34mdata\u001b[0m/\n",
            "\u001b[01;34mkeras\u001b[0m/\n",
            "LICENSE\n",
            "model.png\n",
            "\u001b[01;34mmodels\u001b[0m/\n",
            "\u001b[01;34mpython2\u001b[0m/\n",
            "README.md\n",
            "requirements.txt\n",
            "\u001b[01;34mresults\u001b[0m/\n",
            "\u001b[01;34mrun\u001b[0m/\n",
            "\u001b[01;34mscripts\u001b[0m/\n",
            "TF.2_2_0_2_01_deep_learning_deep_neural_network.ipynb\n",
            "\u001b[01;34mutils\u001b[0m/\n",
            "\u001b[01;34mローカルでの実行結果\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5O_yroxgbY0a"
      },
      "source": [
        "import os\n",
        "\n",
        "from utils.loaders import load_mnist\n",
        "from models.AE import Autoencoder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kI5gjMTWbY0d"
      },
      "source": [
        "## Set parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qdBCu8MbY0e"
      },
      "source": [
        "# run params\n",
        "SECTION = 'vae'\n",
        "RUN_ID = '0001'\n",
        "DATA_NAME = 'digits'\n",
        "RUN_FOLDER = 'run/{}/'.format(SECTION)\n",
        "RUN_FOLDER += '_'.join([RUN_ID, DATA_NAME])\n",
        "\n",
        "if not os.path.exists(RUN_FOLDER):\n",
        "    os.mkdir(RUN_FOLDER)\n",
        "    os.mkdir(os.path.join(RUN_FOLDER, 'viz'))\n",
        "    os.mkdir(os.path.join(RUN_FOLDER, 'images'))\n",
        "    os.mkdir(os.path.join(RUN_FOLDER, 'weights'))\n",
        "\n",
        "MODE =  'build' #'load' #"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbHKdZhebY0g"
      },
      "source": [
        "## Load the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s462TVavbY0h",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f73ba5c2-6b10-4cdf-d505-4b719661878c"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = load_mnist()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLrab2p7bY0j"
      },
      "source": [
        "## Define the structure of the neural network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohDBVTdXbY0k"
      },
      "source": [
        "AE = Autoencoder(\n",
        "    input_dim = (28,28,1)\n",
        "    , encoder_conv_filters = [32,64,64, 64]\n",
        "    , encoder_conv_kernel_size = [3,3,3,3]\n",
        "    , encoder_conv_strides = [1,2,2,1]\n",
        "    , decoder_conv_t_filters = [64,64,32,1]\n",
        "    , decoder_conv_t_kernel_size = [3,3,3,3]\n",
        "    , decoder_conv_t_strides = [1,2,2,1]\n",
        "    , z_dim = 2\n",
        ")\n",
        "\n",
        "if MODE == 'build':\n",
        "    AE.save(RUN_FOLDER)\n",
        "else:\n",
        "    AE.load_weights(os.path.join(RUN_FOLDER, 'weights/weights.h5'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIuhyjuebY0m",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "outputId": "b5be72cb-5470-4603-f612-e9cf009a529d"
      },
      "source": [
        "AE.encoder.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "encoder_input (InputLayer)   [(None, 28, 28, 1)]       0         \n",
            "_________________________________________________________________\n",
            "encoder_conv_0 (Conv2D)      (None, 28, 28, 32)        320       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu (LeakyReLU)      (None, 28, 28, 32)        0         \n",
            "_________________________________________________________________\n",
            "encoder_conv_1 (Conv2D)      (None, 14, 14, 64)        18496     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)    (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "encoder_conv_2 (Conv2D)      (None, 7, 7, 64)          36928     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)    (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "encoder_conv_3 (Conv2D)      (None, 7, 7, 64)          36928     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)    (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 3136)              0         \n",
            "_________________________________________________________________\n",
            "encoder_output (Dense)       (None, 2)                 6274      \n",
            "=================================================================\n",
            "Total params: 98,946\n",
            "Trainable params: 98,946\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-UJLnBDbY0p",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "outputId": "43703cb3-91d0-4631-c601-402328b0069e"
      },
      "source": [
        "AE.decoder.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "decoder_input (InputLayer)   [(None, 2)]               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 3136)              9408      \n",
            "_________________________________________________________________\n",
            "reshape (Reshape)            (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "decoder_conv_t_0 (Conv2DTran (None, 7, 7, 64)          36928     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)    (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "decoder_conv_t_1 (Conv2DTran (None, 14, 14, 64)        36928     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)    (None, 14, 14, 64)        0         \n",
            "_________________________________________________________________\n",
            "decoder_conv_t_2 (Conv2DTran (None, 28, 28, 32)        18464     \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_6 (LeakyReLU)    (None, 28, 28, 32)        0         \n",
            "_________________________________________________________________\n",
            "decoder_conv_t_3 (Conv2DTran (None, 28, 28, 1)         289       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 28, 28, 1)         0         \n",
            "=================================================================\n",
            "Total params: 102,017\n",
            "Trainable params: 102,017\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XK23NVETbY0r"
      },
      "source": [
        "## Train the autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNOMAT3ubY0s"
      },
      "source": [
        "LEARNING_RATE = 0.0005\n",
        "BATCH_SIZE = 32\n",
        "INITIAL_EPOCH = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8bzasm6bY0u"
      },
      "source": [
        "AE.compile(LEARNING_RATE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAZDyaIUbY0w",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "06dfc109-5ff8-4940-8366-de68692b510e"
      },
      "source": [
        "AE.train(     \n",
        "    x_train[:1000]\n",
        "    , batch_size = BATCH_SIZE\n",
        "    , epochs = 200\n",
        "    , run_folder = RUN_FOLDER\n",
        "    , initial_epoch = INITIAL_EPOCH\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1000 samples\n",
            "Epoch 1/200\n",
            "  32/1000 [..............................] - ETA: 3:15 - loss: 0.2307WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.114324). Check your callbacks.\n",
            " 992/1000 [============================>.] - ETA: 0s - loss: 0.1887\n",
            "Epoch 00001: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 7s 7ms/sample - loss: 0.1881\n",
            "Epoch 2/200\n",
            " 992/1000 [============================>.] - ETA: 0s - loss: 0.0991\n",
            "Epoch 00002: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 496us/sample - loss: 0.0989\n",
            "Epoch 3/200\n",
            " 960/1000 [===========================>..] - ETA: 0s - loss: 0.0712\n",
            "Epoch 00003: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 470us/sample - loss: 0.0711\n",
            "Epoch 4/200\n",
            " 992/1000 [============================>.] - ETA: 0s - loss: 0.0623\n",
            "Epoch 00004: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 1s 503us/sample - loss: 0.0623\n",
            "Epoch 5/200\n",
            " 960/1000 [===========================>..] - ETA: 0s - loss: 0.0583\n",
            "Epoch 00005: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 484us/sample - loss: 0.0582\n",
            "Epoch 6/200\n",
            " 960/1000 [===========================>..] - ETA: 0s - loss: 0.0567\n",
            "Epoch 00006: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 478us/sample - loss: 0.0567\n",
            "Epoch 7/200\n",
            " 928/1000 [==========================>...] - ETA: 0s - loss: 0.0556\n",
            "Epoch 00007: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 463us/sample - loss: 0.0557\n",
            "Epoch 8/200\n",
            " 928/1000 [==========================>...] - ETA: 0s - loss: 0.0546\n",
            "Epoch 00008: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 480us/sample - loss: 0.0546\n",
            "Epoch 9/200\n",
            " 992/1000 [============================>.] - ETA: 0s - loss: 0.0540\n",
            "Epoch 00009: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 458us/sample - loss: 0.0540\n",
            "Epoch 10/200\n",
            " 960/1000 [===========================>..] - ETA: 0s - loss: 0.0537\n",
            "Epoch 00010: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 459us/sample - loss: 0.0533\n",
            "Epoch 11/200\n",
            " 960/1000 [===========================>..] - ETA: 0s - loss: 0.0530\n",
            "Epoch 00011: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 465us/sample - loss: 0.0529\n",
            "Epoch 12/200\n",
            " 960/1000 [===========================>..] - ETA: 0s - loss: 0.0524\n",
            "Epoch 00012: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 461us/sample - loss: 0.0525\n",
            "Epoch 13/200\n",
            " 896/1000 [=========================>....] - ETA: 0s - loss: 0.0520\n",
            "Epoch 00013: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 488us/sample - loss: 0.0519\n",
            "Epoch 14/200\n",
            " 992/1000 [============================>.] - ETA: 0s - loss: 0.0516\n",
            "Epoch 00014: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 469us/sample - loss: 0.0516\n",
            "Epoch 15/200\n",
            " 928/1000 [==========================>...] - ETA: 0s - loss: 0.0515\n",
            "Epoch 00015: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 470us/sample - loss: 0.0513\n",
            "Epoch 16/200\n",
            " 992/1000 [============================>.] - ETA: 0s - loss: 0.0509\n",
            "Epoch 00016: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 450us/sample - loss: 0.0509\n",
            "Epoch 17/200\n",
            " 896/1000 [=========================>....] - ETA: 0s - loss: 0.0505\n",
            "Epoch 00017: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 480us/sample - loss: 0.0506\n",
            "Epoch 18/200\n",
            " 960/1000 [===========================>..] - ETA: 0s - loss: 0.0505\n",
            "Epoch 00018: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 461us/sample - loss: 0.0503\n",
            "Epoch 19/200\n",
            " 992/1000 [============================>.] - ETA: 0s - loss: 0.0500\n",
            "Epoch 00019: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 469us/sample - loss: 0.0500\n",
            "Epoch 20/200\n",
            " 960/1000 [===========================>..] - ETA: 0s - loss: 0.0497\n",
            "Epoch 00020: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 474us/sample - loss: 0.0498\n",
            "Epoch 21/200\n",
            " 928/1000 [==========================>...] - ETA: 0s - loss: 0.0496\n",
            "Epoch 00021: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 482us/sample - loss: 0.0495\n",
            "Epoch 22/200\n",
            " 960/1000 [===========================>..] - ETA: 0s - loss: 0.0491\n",
            "Epoch 00022: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 469us/sample - loss: 0.0493\n",
            "Epoch 23/200\n",
            " 992/1000 [============================>.] - ETA: 0s - loss: 0.0490\n",
            "Epoch 00023: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 1s 581us/sample - loss: 0.0490\n",
            "Epoch 24/200\n",
            " 896/1000 [=========================>....] - ETA: 0s - loss: 0.0486\n",
            "Epoch 00024: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 485us/sample - loss: 0.0487\n",
            "Epoch 25/200\n",
            " 928/1000 [==========================>...] - ETA: 0s - loss: 0.0484\n",
            "Epoch 00025: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 486us/sample - loss: 0.0486\n",
            "Epoch 26/200\n",
            " 960/1000 [===========================>..] - ETA: 0s - loss: 0.0484\n",
            "Epoch 00026: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 467us/sample - loss: 0.0483\n",
            "Epoch 27/200\n",
            " 928/1000 [==========================>...] - ETA: 0s - loss: 0.0484\n",
            "Epoch 00027: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 463us/sample - loss: 0.0481\n",
            "Epoch 28/200\n",
            " 960/1000 [===========================>..] - ETA: 0s - loss: 0.0476\n",
            "Epoch 00028: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 465us/sample - loss: 0.0477\n",
            "Epoch 29/200\n",
            " 992/1000 [============================>.] - ETA: 0s - loss: 0.0476\n",
            "Epoch 00029: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 489us/sample - loss: 0.0475\n",
            "Epoch 30/200\n",
            " 928/1000 [==========================>...] - ETA: 0s - loss: 0.0474\n",
            "Epoch 00030: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 460us/sample - loss: 0.0473\n",
            "Epoch 31/200\n",
            " 960/1000 [===========================>..] - ETA: 0s - loss: 0.0468\n",
            "Epoch 00031: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 483us/sample - loss: 0.0472\n",
            "Epoch 32/200\n",
            " 896/1000 [=========================>....] - ETA: 0s - loss: 0.0474\n",
            "Epoch 00032: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 479us/sample - loss: 0.0473\n",
            "Epoch 33/200\n",
            " 960/1000 [===========================>..] - ETA: 0s - loss: 0.0468\n",
            "Epoch 00033: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 464us/sample - loss: 0.0467\n",
            "Epoch 34/200\n",
            " 960/1000 [===========================>..] - ETA: 0s - loss: 0.0467\n",
            "Epoch 00034: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 474us/sample - loss: 0.0467\n",
            "Epoch 35/200\n",
            " 960/1000 [===========================>..] - ETA: 0s - loss: 0.0466\n",
            "Epoch 00035: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 479us/sample - loss: 0.0464\n",
            "Epoch 36/200\n",
            " 960/1000 [===========================>..] - ETA: 0s - loss: 0.0462\n",
            "Epoch 00036: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 452us/sample - loss: 0.0461\n",
            "Epoch 37/200\n",
            " 992/1000 [============================>.] - ETA: 0s - loss: 0.0459\n",
            "Epoch 00037: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 463us/sample - loss: 0.0458\n",
            "Epoch 38/200\n",
            " 992/1000 [============================>.] - ETA: 0s - loss: 0.0456\n",
            "Epoch 00038: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 457us/sample - loss: 0.0456\n",
            "Epoch 39/200\n",
            " 960/1000 [===========================>..] - ETA: 0s - loss: 0.0457\n",
            "Epoch 00039: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 458us/sample - loss: 0.0458\n",
            "Epoch 40/200\n",
            " 960/1000 [===========================>..] - ETA: 0s - loss: 0.0453\n",
            "Epoch 00040: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 477us/sample - loss: 0.0453\n",
            "Epoch 41/200\n",
            " 992/1000 [============================>.] - ETA: 0s - loss: 0.0450\n",
            "Epoch 00041: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 1s 596us/sample - loss: 0.0450\n",
            "Epoch 42/200\n",
            " 960/1000 [===========================>..] - ETA: 0s - loss: 0.0450\n",
            "Epoch 00042: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 464us/sample - loss: 0.0450\n",
            "Epoch 43/200\n",
            " 992/1000 [============================>.] - ETA: 0s - loss: 0.0449\n",
            "Epoch 00043: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 456us/sample - loss: 0.0449\n",
            "Epoch 44/200\n",
            " 992/1000 [============================>.] - ETA: 0s - loss: 0.0446\n",
            "Epoch 00044: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 459us/sample - loss: 0.0445\n",
            "Epoch 45/200\n",
            " 960/1000 [===========================>..] - ETA: 0s - loss: 0.0442\n",
            "Epoch 00045: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 460us/sample - loss: 0.0443\n",
            "Epoch 46/200\n",
            " 928/1000 [==========================>...] - ETA: 0s - loss: 0.0442\n",
            "Epoch 00046: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 472us/sample - loss: 0.0442\n",
            "Epoch 47/200\n",
            " 960/1000 [===========================>..] - ETA: 0s - loss: 0.0442\n",
            "Epoch 00047: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 464us/sample - loss: 0.0442\n",
            "Epoch 48/200\n",
            " 960/1000 [===========================>..] - ETA: 0s - loss: 0.0439\n",
            "Epoch 00048: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 461us/sample - loss: 0.0441\n",
            "Epoch 49/200\n",
            " 960/1000 [===========================>..] - ETA: 0s - loss: 0.0441\n",
            "Epoch 00049: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 465us/sample - loss: 0.0440\n",
            "Epoch 50/200\n",
            "WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.145360). Check your callbacks.\n",
            " 960/1000 [===========================>..] - ETA: 0s - loss: 0.0433\n",
            "Epoch 00050: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 1s 575us/sample - loss: 0.0436\n",
            "Epoch 51/200\n",
            " 992/1000 [============================>.] - ETA: 0s - loss: 0.0436\n",
            "Epoch 00051: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 482us/sample - loss: 0.0436\n",
            "Epoch 52/200\n",
            " 896/1000 [=========================>....] - ETA: 0s - loss: 0.0437\n",
            "Epoch 00052: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 469us/sample - loss: 0.0437\n",
            "Epoch 53/200\n",
            " 960/1000 [===========================>..] - ETA: 0s - loss: 0.0433\n",
            "Epoch 00053: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 465us/sample - loss: 0.0432\n",
            "Epoch 54/200\n",
            " 928/1000 [==========================>...] - ETA: 0s - loss: 0.0429\n",
            "Epoch 00054: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 487us/sample - loss: 0.0430\n",
            "Epoch 55/200\n",
            " 928/1000 [==========================>...] - ETA: 0s - loss: 0.0429\n",
            "Epoch 00055: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 475us/sample - loss: 0.0431\n",
            "Epoch 56/200\n",
            " 896/1000 [=========================>....] - ETA: 0s - loss: 0.0433\n",
            "Epoch 00056: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 474us/sample - loss: 0.0434\n",
            "Epoch 57/200\n",
            " 960/1000 [===========================>..] - ETA: 0s - loss: 0.0428\n",
            "Epoch 00057: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 460us/sample - loss: 0.0426\n",
            "Epoch 58/200\n",
            "WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.145911). Check your callbacks.\n",
            " 896/1000 [=========================>....] - ETA: 0s - loss: 0.0422\n",
            "Epoch 00058: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 1s 581us/sample - loss: 0.0423\n",
            "Epoch 59/200\n",
            " 992/1000 [============================>.] - ETA: 0s - loss: 0.0422\n",
            "Epoch 00059: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 461us/sample - loss: 0.0422\n",
            "Epoch 60/200\n",
            " 960/1000 [===========================>..] - ETA: 0s - loss: 0.0424\n",
            "Epoch 00060: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 499us/sample - loss: 0.0422\n",
            "Epoch 61/200\n",
            " 992/1000 [============================>.] - ETA: 0s - loss: 0.0422\n",
            "Epoch 00061: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 461us/sample - loss: 0.0422\n",
            "Epoch 62/200\n",
            " 896/1000 [=========================>....] - ETA: 0s - loss: 0.0421\n",
            "Epoch 00062: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 488us/sample - loss: 0.0422\n",
            "Epoch 63/200\n",
            " 960/1000 [===========================>..] - ETA: 0s - loss: 0.0419\n",
            "Epoch 00063: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 452us/sample - loss: 0.0418\n",
            "Epoch 64/200\n",
            " 928/1000 [==========================>...] - ETA: 0s - loss: 0.0420\n",
            "Epoch 00064: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 473us/sample - loss: 0.0421\n",
            "Epoch 65/200\n",
            " 928/1000 [==========================>...] - ETA: 0s - loss: 0.0415\n",
            "Epoch 00065: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 485us/sample - loss: 0.0415\n",
            "Epoch 66/200\n",
            "WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.142818). Check your callbacks.\n",
            " 896/1000 [=========================>....] - ETA: 0s - loss: 0.0412\n",
            "Epoch 00066: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 1s 580us/sample - loss: 0.0415\n",
            "Epoch 67/200\n",
            " 928/1000 [==========================>...] - ETA: 0s - loss: 0.0413\n",
            "Epoch 00067: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 461us/sample - loss: 0.0412\n",
            "Epoch 68/200\n",
            " 960/1000 [===========================>..] - ETA: 0s - loss: 0.0415\n",
            "Epoch 00068: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 476us/sample - loss: 0.0413\n",
            "Epoch 69/200\n",
            " 896/1000 [=========================>....] - ETA: 0s - loss: 0.0409\n",
            "Epoch 00069: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 479us/sample - loss: 0.0409\n",
            "Epoch 70/200\n",
            " 864/1000 [========================>.....] - ETA: 0s - loss: 0.0405\n",
            "Epoch 00070: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 474us/sample - loss: 0.0407\n",
            "Epoch 71/200\n",
            " 928/1000 [==========================>...] - ETA: 0s - loss: 0.0405\n",
            "Epoch 00071: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 458us/sample - loss: 0.0406\n",
            "Epoch 72/200\n",
            " 992/1000 [============================>.] - ETA: 0s - loss: 0.0406\n",
            "Epoch 00072: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 481us/sample - loss: 0.0405\n",
            "Epoch 73/200\n",
            " 992/1000 [============================>.] - ETA: 0s - loss: 0.0406\n",
            "Epoch 00073: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 444us/sample - loss: 0.0406\n",
            "Epoch 74/200\n",
            " 960/1000 [===========================>..] - ETA: 0s - loss: 0.0402\n",
            "Epoch 00074: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 465us/sample - loss: 0.0403\n",
            "Epoch 75/200\n",
            " 960/1000 [===========================>..] - ETA: 0s - loss: 0.0405\n",
            "Epoch 00075: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 485us/sample - loss: 0.0405\n",
            "Epoch 76/200\n",
            " 896/1000 [=========================>....] - ETA: 0s - loss: 0.0410\n",
            "Epoch 00076: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 1s 514us/sample - loss: 0.0407\n",
            "Epoch 77/200\n",
            " 992/1000 [============================>.] - ETA: 0s - loss: 0.0403\n",
            "Epoch 00077: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 483us/sample - loss: 0.0403\n",
            "Epoch 78/200\n",
            " 928/1000 [==========================>...] - ETA: 0s - loss: 0.0404\n",
            "Epoch 00078: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 460us/sample - loss: 0.0404\n",
            "Epoch 79/200\n",
            " 928/1000 [==========================>...] - ETA: 0s - loss: 0.0405\n",
            "Epoch 00079: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 489us/sample - loss: 0.0406\n",
            "Epoch 80/200\n",
            " 928/1000 [==========================>...] - ETA: 0s - loss: 0.0404\n",
            "Epoch 00080: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 472us/sample - loss: 0.0401\n",
            "Epoch 81/200\n",
            " 928/1000 [==========================>...] - ETA: 0s - loss: 0.0397\n",
            "Epoch 00081: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 462us/sample - loss: 0.0398\n",
            "Epoch 82/200\n",
            " 864/1000 [========================>.....] - ETA: 0s - loss: 0.0396\n",
            "Epoch 00082: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 1s 508us/sample - loss: 0.0396\n",
            "Epoch 83/200\n",
            " 992/1000 [============================>.] - ETA: 0s - loss: 0.0394\n",
            "Epoch 00083: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 498us/sample - loss: 0.0395\n",
            "Epoch 84/200\n",
            " 928/1000 [==========================>...] - ETA: 0s - loss: 0.0399\n",
            "Epoch 00084: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 463us/sample - loss: 0.0398\n",
            "Epoch 85/200\n",
            " 896/1000 [=========================>....] - ETA: 0s - loss: 0.0395\n",
            "Epoch 00085: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 472us/sample - loss: 0.0393\n",
            "Epoch 86/200\n",
            " 928/1000 [==========================>...] - ETA: 0s - loss: 0.0395\n",
            "Epoch 00086: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 469us/sample - loss: 0.0395\n",
            "Epoch 87/200\n",
            " 928/1000 [==========================>...] - ETA: 0s - loss: 0.0396\n",
            "Epoch 00087: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 472us/sample - loss: 0.0395\n",
            "Epoch 88/200\n",
            " 928/1000 [==========================>...] - ETA: 0s - loss: 0.0393\n",
            "Epoch 00088: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 472us/sample - loss: 0.0392\n",
            "Epoch 89/200\n",
            " 992/1000 [============================>.] - ETA: 0s - loss: 0.0393\n",
            "Epoch 00089: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 469us/sample - loss: 0.0392\n",
            "Epoch 90/200\n",
            " 928/1000 [==========================>...] - ETA: 0s - loss: 0.0386\n",
            "Epoch 00090: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 489us/sample - loss: 0.0390\n",
            "Epoch 91/200\n",
            "WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.149109). Check your callbacks.\n",
            " 928/1000 [==========================>...] - ETA: 0s - loss: 0.0390\n",
            "Epoch 00091: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 1s 586us/sample - loss: 0.0391\n",
            "Epoch 92/200\n",
            " 960/1000 [===========================>..] - ETA: 0s - loss: 0.0393\n",
            "Epoch 00092: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 464us/sample - loss: 0.0394\n",
            "Epoch 93/200\n",
            " 896/1000 [=========================>....] - ETA: 0s - loss: 0.0394\n",
            "Epoch 00093: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 499us/sample - loss: 0.0391\n",
            "Epoch 94/200\n",
            " 992/1000 [============================>.] - ETA: 0s - loss: 0.0386\n",
            "Epoch 00094: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 498us/sample - loss: 0.0386\n",
            "Epoch 95/200\n",
            " 960/1000 [===========================>..] - ETA: 0s - loss: 0.0389\n",
            "Epoch 00095: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 475us/sample - loss: 0.0387\n",
            "Epoch 96/200\n",
            " 960/1000 [===========================>..] - ETA: 0s - loss: 0.0387\n",
            "Epoch 00096: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 470us/sample - loss: 0.0388\n",
            "Epoch 97/200\n",
            " 992/1000 [============================>.] - ETA: 0s - loss: 0.0387\n",
            "Epoch 00097: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 489us/sample - loss: 0.0388\n",
            "Epoch 98/200\n",
            " 992/1000 [============================>.] - ETA: 0s - loss: 0.0390\n",
            "Epoch 00098: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 473us/sample - loss: 0.0390\n",
            "Epoch 99/200\n",
            " 928/1000 [==========================>...] - ETA: 0s - loss: 0.0390\n",
            "Epoch 00099: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 483us/sample - loss: 0.0389\n",
            "Epoch 100/200\n",
            " 928/1000 [==========================>...] - ETA: 0s - loss: 0.0383\n",
            "Epoch 00100: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 496us/sample - loss: 0.0383\n",
            "Epoch 101/200\n",
            " 928/1000 [==========================>...] - ETA: 0s - loss: 0.0389\n",
            "Epoch 00101: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 481us/sample - loss: 0.0388\n",
            "Epoch 102/200\n",
            " 960/1000 [===========================>..] - ETA: 0s - loss: 0.0380\n",
            "Epoch 00102: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 463us/sample - loss: 0.0381\n",
            "Epoch 103/200\n",
            " 960/1000 [===========================>..] - ETA: 0s - loss: 0.0377\n",
            "Epoch 00103: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 468us/sample - loss: 0.0380\n",
            "Epoch 104/200\n",
            " 960/1000 [===========================>..] - ETA: 0s - loss: 0.0380\n",
            "Epoch 00104: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 1s 509us/sample - loss: 0.0382\n",
            "Epoch 105/200\n",
            " 960/1000 [===========================>..] - ETA: 0s - loss: 0.0383\n",
            "Epoch 00105: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 458us/sample - loss: 0.0384\n",
            "Epoch 106/200\n",
            " 992/1000 [============================>.] - ETA: 0s - loss: 0.0383\n",
            "Epoch 00106: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 453us/sample - loss: 0.0383\n",
            "Epoch 107/200\n",
            " 960/1000 [===========================>..] - ETA: 0s - loss: 0.0382\n",
            "Epoch 00107: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 468us/sample - loss: 0.0379\n",
            "Epoch 108/200\n",
            "WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.140772). Check your callbacks.\n",
            " 960/1000 [===========================>..] - ETA: 0s - loss: 0.0379\n",
            "Epoch 00108: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 1s 566us/sample - loss: 0.0379\n",
            "Epoch 109/200\n",
            " 960/1000 [===========================>..] - ETA: 0s - loss: 0.0377\n",
            "Epoch 00109: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 470us/sample - loss: 0.0378\n",
            "Epoch 110/200\n",
            " 960/1000 [===========================>..] - ETA: 0s - loss: 0.0381\n",
            "Epoch 00110: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 460us/sample - loss: 0.0379\n",
            "Epoch 111/200\n",
            " 896/1000 [=========================>....] - ETA: 0s - loss: 0.0376\n",
            "Epoch 00111: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 481us/sample - loss: 0.0380\n",
            "Epoch 112/200\n",
            " 960/1000 [===========================>..] - ETA: 0s - loss: 0.0381\n",
            "Epoch 00112: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 473us/sample - loss: 0.0381\n",
            "Epoch 113/200\n",
            " 896/1000 [=========================>....] - ETA: 0s - loss: 0.0374\n",
            "Epoch 00113: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 493us/sample - loss: 0.0379\n",
            "Epoch 114/200\n",
            " 896/1000 [=========================>....] - ETA: 0s - loss: 0.0376\n",
            "Epoch 00114: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 468us/sample - loss: 0.0376\n",
            "Epoch 115/200\n",
            " 992/1000 [============================>.] - ETA: 0s - loss: 0.0376\n",
            "Epoch 00115: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 454us/sample - loss: 0.0375\n",
            "Epoch 116/200\n",
            " 960/1000 [===========================>..] - ETA: 0s - loss: 0.0379\n",
            "Epoch 00116: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 1s 604us/sample - loss: 0.0378\n",
            "Epoch 117/200\n",
            " 928/1000 [==========================>...] - ETA: 0s - loss: 0.0376\n",
            "Epoch 00117: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 468us/sample - loss: 0.0377\n",
            "Epoch 118/200\n",
            " 960/1000 [===========================>..] - ETA: 0s - loss: 0.0379\n",
            "Epoch 00118: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 463us/sample - loss: 0.0379\n",
            "Epoch 119/200\n",
            " 960/1000 [===========================>..] - ETA: 0s - loss: 0.0376\n",
            "Epoch 00119: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 482us/sample - loss: 0.0374\n",
            "Epoch 120/200\n",
            " 896/1000 [=========================>....] - ETA: 0s - loss: 0.0371\n",
            "Epoch 00120: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 467us/sample - loss: 0.0373\n",
            "Epoch 121/200\n",
            " 960/1000 [===========================>..] - ETA: 0s - loss: 0.0370\n",
            "Epoch 00121: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 488us/sample - loss: 0.0371\n",
            "Epoch 122/200\n",
            " 960/1000 [===========================>..] - ETA: 0s - loss: 0.0374\n",
            "Epoch 00122: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 470us/sample - loss: 0.0374\n",
            "Epoch 123/200\n",
            " 992/1000 [============================>.] - ETA: 0s - loss: 0.0374\n",
            "Epoch 00123: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 460us/sample - loss: 0.0374\n",
            "Epoch 124/200\n",
            " 960/1000 [===========================>..] - ETA: 0s - loss: 0.0377\n",
            "Epoch 00124: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 466us/sample - loss: 0.0377\n",
            "Epoch 125/200\n",
            " 960/1000 [===========================>..] - ETA: 0s - loss: 0.0372\n",
            "Epoch 00125: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 1s 617us/sample - loss: 0.0373\n",
            "Epoch 126/200\n",
            " 992/1000 [============================>.] - ETA: 0s - loss: 0.0374\n",
            "Epoch 00126: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 452us/sample - loss: 0.0373\n",
            "Epoch 127/200\n",
            " 992/1000 [============================>.] - ETA: 0s - loss: 0.0368\n",
            "Epoch 00127: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 456us/sample - loss: 0.0368\n",
            "Epoch 128/200\n",
            " 928/1000 [==========================>...] - ETA: 0s - loss: 0.0370\n",
            "Epoch 00128: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 482us/sample - loss: 0.0370\n",
            "Epoch 129/200\n",
            " 928/1000 [==========================>...] - ETA: 0s - loss: 0.0367\n",
            "Epoch 00129: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 476us/sample - loss: 0.0368\n",
            "Epoch 130/200\n",
            " 960/1000 [===========================>..] - ETA: 0s - loss: 0.0373\n",
            "Epoch 00130: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 464us/sample - loss: 0.0372\n",
            "Epoch 131/200\n",
            " 928/1000 [==========================>...] - ETA: 0s - loss: 0.0375\n",
            "Epoch 00131: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 470us/sample - loss: 0.0373\n",
            "Epoch 132/200\n",
            " 928/1000 [==========================>...] - ETA: 0s - loss: 0.0371\n",
            "Epoch 00132: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 471us/sample - loss: 0.0370\n",
            "Epoch 133/200\n",
            " 928/1000 [==========================>...] - ETA: 0s - loss: 0.0366\n",
            "Epoch 00133: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 469us/sample - loss: 0.0369\n",
            "Epoch 134/200\n",
            " 864/1000 [========================>.....] - ETA: 0s - loss: 0.0370\n",
            "Epoch 00134: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 494us/sample - loss: 0.0369\n",
            "Epoch 135/200\n",
            " 992/1000 [============================>.] - ETA: 0s - loss: 0.0370\n",
            "Epoch 00135: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 460us/sample - loss: 0.0370\n",
            "Epoch 136/200\n",
            " 928/1000 [==========================>...] - ETA: 0s - loss: 0.0366\n",
            "Epoch 00136: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 466us/sample - loss: 0.0366\n",
            "Epoch 137/200\n",
            " 960/1000 [===========================>..] - ETA: 0s - loss: 0.0363\n",
            "Epoch 00137: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 454us/sample - loss: 0.0362\n",
            "Epoch 138/200\n",
            " 960/1000 [===========================>..] - ETA: 0s - loss: 0.0367\n",
            "Epoch 00138: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 474us/sample - loss: 0.0365\n",
            "Epoch 139/200\n",
            " 992/1000 [============================>.] - ETA: 0s - loss: 0.0366\n",
            "Epoch 00139: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 459us/sample - loss: 0.0366\n",
            "Epoch 140/200\n",
            " 960/1000 [===========================>..] - ETA: 0s - loss: 0.0367\n",
            "Epoch 00140: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 488us/sample - loss: 0.0366\n",
            "Epoch 141/200\n",
            " 960/1000 [===========================>..] - ETA: 0s - loss: 0.0366\n",
            "Epoch 00141: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 456us/sample - loss: 0.0366\n",
            "Epoch 142/200\n",
            " 928/1000 [==========================>...] - ETA: 0s - loss: 0.0366\n",
            "Epoch 00142: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 472us/sample - loss: 0.0370\n",
            "Epoch 143/200\n",
            " 960/1000 [===========================>..] - ETA: 0s - loss: 0.0371\n",
            "Epoch 00143: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 483us/sample - loss: 0.0369\n",
            "Epoch 144/200\n",
            " 928/1000 [==========================>...] - ETA: 0s - loss: 0.0366\n",
            "Epoch 00144: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 466us/sample - loss: 0.0365\n",
            "Epoch 145/200\n",
            " 896/1000 [=========================>....] - ETA: 0s - loss: 0.0372\n",
            "Epoch 00145: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 462us/sample - loss: 0.0372\n",
            "Epoch 146/200\n",
            " 992/1000 [============================>.] - ETA: 0s - loss: 0.0367\n",
            "Epoch 00146: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 458us/sample - loss: 0.0367\n",
            "Epoch 147/200\n",
            " 928/1000 [==========================>...] - ETA: 0s - loss: 0.0363\n",
            "Epoch 00147: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 470us/sample - loss: 0.0364\n",
            "Epoch 148/200\n",
            " 992/1000 [============================>.] - ETA: 0s - loss: 0.0363\n",
            "Epoch 00148: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 457us/sample - loss: 0.0363\n",
            "Epoch 149/200\n",
            " 864/1000 [========================>.....] - ETA: 0s - loss: 0.0364\n",
            "Epoch 00149: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 497us/sample - loss: 0.0365\n",
            "Epoch 150/200\n",
            " 960/1000 [===========================>..] - ETA: 0s - loss: 0.0364\n",
            "Epoch 00150: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 460us/sample - loss: 0.0363\n",
            "Epoch 151/200\n",
            " 928/1000 [==========================>...] - ETA: 0s - loss: 0.0364\n",
            "Epoch 00151: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 470us/sample - loss: 0.0363\n",
            "Epoch 152/200\n",
            "WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.147600). Check your callbacks.\n",
            " 928/1000 [==========================>...] - ETA: 0s - loss: 0.0363\n",
            "Epoch 00152: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 1s 595us/sample - loss: 0.0362\n",
            "Epoch 153/200\n",
            " 928/1000 [==========================>...] - ETA: 0s - loss: 0.0359\n",
            "Epoch 00153: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 459us/sample - loss: 0.0359\n",
            "Epoch 154/200\n",
            " 992/1000 [============================>.] - ETA: 0s - loss: 0.0359\n",
            "Epoch 00154: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 448us/sample - loss: 0.0359\n",
            "Epoch 155/200\n",
            " 960/1000 [===========================>..] - ETA: 0s - loss: 0.0361\n",
            "Epoch 00155: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 479us/sample - loss: 0.0362\n",
            "Epoch 156/200\n",
            " 992/1000 [============================>.] - ETA: 0s - loss: 0.0357\n",
            "Epoch 00156: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 462us/sample - loss: 0.0358\n",
            "Epoch 157/200\n",
            " 928/1000 [==========================>...] - ETA: 0s - loss: 0.0358\n",
            "Epoch 00157: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 480us/sample - loss: 0.0358\n",
            "Epoch 158/200\n",
            " 960/1000 [===========================>..] - ETA: 0s - loss: 0.0362\n",
            "Epoch 00158: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 483us/sample - loss: 0.0360\n",
            "Epoch 159/200\n",
            " 992/1000 [============================>.] - ETA: 0s - loss: 0.0356\n",
            "Epoch 00159: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 1s 509us/sample - loss: 0.0358\n",
            "Epoch 160/200\n",
            " 960/1000 [===========================>..] - ETA: 0s - loss: 0.0361\n",
            "Epoch 00160: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 494us/sample - loss: 0.0361\n",
            "Epoch 161/200\n",
            "WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.195287). Check your callbacks.\n",
            " 992/1000 [============================>.] - ETA: 0s - loss: 0.0361\n",
            "Epoch 00161: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 1s 682us/sample - loss: 0.0361\n",
            "Epoch 162/200\n",
            " 992/1000 [============================>.] - ETA: 0s - loss: 0.0357\n",
            "Epoch 00162: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 489us/sample - loss: 0.0358\n",
            "Epoch 163/200\n",
            " 896/1000 [=========================>....] - ETA: 0s - loss: 0.0355\n",
            "Epoch 00163: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 1s 518us/sample - loss: 0.0359\n",
            "Epoch 164/200\n",
            " 928/1000 [==========================>...] - ETA: 0s - loss: 0.0360\n",
            "Epoch 00164: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 1s 503us/sample - loss: 0.0359\n",
            "Epoch 165/200\n",
            " 960/1000 [===========================>..] - ETA: 0s - loss: 0.0356\n",
            "Epoch 00165: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 1s 556us/sample - loss: 0.0357\n",
            "Epoch 166/200\n",
            " 928/1000 [==========================>...] - ETA: 0s - loss: 0.0354\n",
            "Epoch 00166: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 1s 504us/sample - loss: 0.0355\n",
            "Epoch 167/200\n",
            " 960/1000 [===========================>..] - ETA: 0s - loss: 0.0355\n",
            "Epoch 00167: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 1s 527us/sample - loss: 0.0357\n",
            "Epoch 168/200\n",
            " 992/1000 [============================>.] - ETA: 0s - loss: 0.0355\n",
            "Epoch 00168: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 1s 652us/sample - loss: 0.0355\n",
            "Epoch 169/200\n",
            " 992/1000 [============================>.] - ETA: 0s - loss: 0.0356\n",
            "Epoch 00169: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 1s 512us/sample - loss: 0.0356\n",
            "Epoch 170/200\n",
            " 928/1000 [==========================>...] - ETA: 0s - loss: 0.0362\n",
            "Epoch 00170: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 1s 524us/sample - loss: 0.0360\n",
            "Epoch 171/200\n",
            " 960/1000 [===========================>..] - ETA: 0s - loss: 0.0357\n",
            "Epoch 00171: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 1s 536us/sample - loss: 0.0358\n",
            "Epoch 172/200\n",
            " 864/1000 [========================>.....] - ETA: 0s - loss: 0.0358\n",
            "Epoch 00172: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 1s 506us/sample - loss: 0.0357\n",
            "Epoch 173/200\n",
            " 896/1000 [=========================>....] - ETA: 0s - loss: 0.0358\n",
            "Epoch 00173: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 1s 526us/sample - loss: 0.0357\n",
            "Epoch 174/200\n",
            " 992/1000 [============================>.] - ETA: 0s - loss: 0.0355\n",
            "Epoch 00174: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 1s 532us/sample - loss: 0.0355\n",
            "Epoch 175/200\n",
            " 896/1000 [=========================>....] - ETA: 0s - loss: 0.0353\n",
            "Epoch 00175: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 1s 509us/sample - loss: 0.0358\n",
            "Epoch 176/200\n",
            "WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.153877). Check your callbacks.\n",
            " 992/1000 [============================>.] - ETA: 0s - loss: 0.0359\n",
            "Epoch 00176: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 1s 636us/sample - loss: 0.0359\n",
            "Epoch 177/200\n",
            " 992/1000 [============================>.] - ETA: 0s - loss: 0.0358\n",
            "Epoch 00177: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 454us/sample - loss: 0.0358\n",
            "Epoch 178/200\n",
            " 992/1000 [============================>.] - ETA: 0s - loss: 0.0356\n",
            "Epoch 00178: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 1s 513us/sample - loss: 0.0356\n",
            "Epoch 179/200\n",
            " 992/1000 [============================>.] - ETA: 0s - loss: 0.0356\n",
            "Epoch 00179: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 489us/sample - loss: 0.0355\n",
            "Epoch 180/200\n",
            " 896/1000 [=========================>....] - ETA: 0s - loss: 0.0352\n",
            "Epoch 00180: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 488us/sample - loss: 0.0353\n",
            "Epoch 181/200\n",
            " 928/1000 [==========================>...] - ETA: 0s - loss: 0.0358\n",
            "Epoch 00181: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 469us/sample - loss: 0.0357\n",
            "Epoch 182/200\n",
            " 960/1000 [===========================>..] - ETA: 0s - loss: 0.0353\n",
            "Epoch 00182: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 458us/sample - loss: 0.0351\n",
            "Epoch 183/200\n",
            " 960/1000 [===========================>..] - ETA: 0s - loss: 0.0353\n",
            "Epoch 00183: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 452us/sample - loss: 0.0353\n",
            "Epoch 184/200\n",
            " 928/1000 [==========================>...] - ETA: 0s - loss: 0.0356\n",
            "Epoch 00184: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 1s 559us/sample - loss: 0.0355\n",
            "Epoch 185/200\n",
            " 992/1000 [============================>.] - ETA: 0s - loss: 0.0354\n",
            "Epoch 00185: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 447us/sample - loss: 0.0354\n",
            "Epoch 186/200\n",
            " 928/1000 [==========================>...] - ETA: 0s - loss: 0.0357\n",
            "Epoch 00186: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 484us/sample - loss: 0.0356\n",
            "Epoch 187/200\n",
            " 992/1000 [============================>.] - ETA: 0s - loss: 0.0352\n",
            "Epoch 00187: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 466us/sample - loss: 0.0353\n",
            "Epoch 188/200\n",
            " 960/1000 [===========================>..] - ETA: 0s - loss: 0.0349\n",
            "Epoch 00188: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 466us/sample - loss: 0.0350\n",
            "Epoch 189/200\n",
            " 960/1000 [===========================>..] - ETA: 0s - loss: 0.0350\n",
            "Epoch 00189: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 454us/sample - loss: 0.0348\n",
            "Epoch 190/200\n",
            " 928/1000 [==========================>...] - ETA: 0s - loss: 0.0349\n",
            "Epoch 00190: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 464us/sample - loss: 0.0350\n",
            "Epoch 191/200\n",
            " 896/1000 [=========================>....] - ETA: 0s - loss: 0.0355\n",
            "Epoch 00191: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 1s 501us/sample - loss: 0.0353\n",
            "Epoch 192/200\n",
            " 928/1000 [==========================>...] - ETA: 0s - loss: 0.0349\n",
            "Epoch 00192: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 478us/sample - loss: 0.0348\n",
            "Epoch 193/200\n",
            "WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.147570). Check your callbacks.\n",
            " 960/1000 [===========================>..] - ETA: 0s - loss: 0.0347\n",
            "Epoch 00193: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 1s 582us/sample - loss: 0.0348\n",
            "Epoch 194/200\n",
            " 960/1000 [===========================>..] - ETA: 0s - loss: 0.0355\n",
            "Epoch 00194: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 489us/sample - loss: 0.0354\n",
            "Epoch 195/200\n",
            " 960/1000 [===========================>..] - ETA: 0s - loss: 0.0354\n",
            "Epoch 00195: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 486us/sample - loss: 0.0355\n",
            "Epoch 196/200\n",
            " 960/1000 [===========================>..] - ETA: 0s - loss: 0.0354\n",
            "Epoch 00196: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 467us/sample - loss: 0.0353\n",
            "Epoch 197/200\n",
            " 960/1000 [===========================>..] - ETA: 0s - loss: 0.0352\n",
            "Epoch 00197: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 468us/sample - loss: 0.0350\n",
            "Epoch 198/200\n",
            " 960/1000 [===========================>..] - ETA: 0s - loss: 0.0346\n",
            "Epoch 00198: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 487us/sample - loss: 0.0347\n",
            "Epoch 199/200\n",
            " 928/1000 [==========================>...] - ETA: 0s - loss: 0.0349\n",
            "Epoch 00199: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 483us/sample - loss: 0.0348\n",
            "Epoch 200/200\n",
            " 992/1000 [============================>.] - ETA: 0s - loss: 0.0346\n",
            "Epoch 00200: saving model to run/vae/0001_digits/weights/weights.h5\n",
            "1000/1000 [==============================] - 0s 447us/sample - loss: 0.0346\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GODPLG7qcv_V"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}